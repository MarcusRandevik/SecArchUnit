# Systematic mapping, 2020-03-11

## What have we done

Systematic mapping of security patterns, rules, and common weaknesses.  
Categorized these by security concern, and then merged the ones that were similar.

The mapping contains only things that, from our intuition, should be possible to statically analyze.

We have investigated how ArchUnit processes and builds its own representation of Java code.  
Looked at ASM, the library that ArchUnit uses to process Java bytecode, and 
some features of this library that would support extensions to ArchUnit.  
For example, we *may* be able to analyze local variable instructions and the constant pool to deduce
how objects are passed around.

## Feedback

Consider contacting the author of ArchUnit for pointers.

It is fine to aim for a minimally invasive approach that doesn't need any additional constructs.  
If you hit a wall with this approach, consider making it the responsibility of the developer to put the necessary information in the code (e.g. language extension, framework, annotation).  
The goal is not to create the best static analysis tool, but to show that it is possible to enforce the constraints.

If we manage to implement the constraints without an extension to the tool, that will still make for an interesting thesis.
But extensions will probably be necessary.  
It is fine to mix multiple approaches, but try to make the solution elegant.

Good that you have started thinking about concepts. It is good if you can reuse concepts in multiple constraints, "have a toolbox of concepts".

Next, select a subset of the mapped concerns and work on them.  
Be honest when selecting; not only the easiest ones.  
Aim for 5-7 constraints, preferably one from each security concern.  
Prioritize grouped concepts as they appear in several sources.

> Decide today what constraints you will work on, so that we can have an initial assessment on March 20.

## Validation

### Evolution approach

Show that the tool is able to enforce constraints continuously over time.  
Look at the evolution of the system; 3-4 snapshots over time.  
Take the first snapshot, extract the architecture and model the rules.  
Then for each snapshot, run the tool.  
False positives: easy to detect. Look at the flagged locations and determine if they are valid.  
False negatives: more subtle. Have to establish the ground truth. Manually inspect the differences between the snapshots and find violations.

### Injection approach

Inject faults randomly according to a decided protocol.

This introduces a subjectivity since we created the tool. But this may be acceptable given the setup of the project.

Could also use this in combination with the evolution approach.

Whichever approach we choose, we need to have a clear plan.

### Selection of systems

Would like to aim for 2 or 3 smaller systems, as each system will require extensive work.

We find it difficult to select systems for the validation. 
Finding ones that are of reasonable size and are not merely acting as glue between a collection of libraries.

We could possibly use systems from Katja's models paper;

* "iTrust" ~28,000 lines
* "CoCoMO" ~5,000 lines
* "Eclipse secure storage" ~3,000 lines

This would have the benefit that we are using someone else's work to establish the ground truth, which increases our credibility.  
Do check whether there is enough history of their evolution.

## Half-time presentation

Due 10 weeks into the thesis.

Contact Michel (examiner) to decide on a date: March 26, 1 PM. Send report by March 23.

In the report, detail what we have been doing; getting a collection of security constraints, what sources have we analyzed, which constraints have we found, describe how we model them briefly.

By that meeting, be able to show the results of the directions we are taking, that there is technical work that has been done.

> Aim for 10 pages of good content.
> This will essentially be a draft of your thesis, so write it in the same document.

## What's next

**Now**  
Produce half-time report. Select constraints to work on and start implementing them. Look at whether the systems have enough history to be used in validation.

**2020-03-20**  
Synchronization meeting over Skype at 11:00.

**2020-03-23**
Send half-time report to Michel.

**Other**  
R will be absent April 6-17.
